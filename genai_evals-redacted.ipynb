{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation with Azure AI Foundry\n",
    "\n",
    "This notebook demonstrates how to evaluate data using custom evaluators and send the results to [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-studio/what-is-ai-studio).\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- An Azure subscription.\n",
    "- An Azure AI Foundry workspace.\n",
    "- An Azure AI Foundry project.\n",
    "- An Azure OpenAI resource.\n",
    "\n",
    "### Install the required packages\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Create the following environment variables or add them to an `.env` file\n",
    "\n",
    "```bash\n",
    "AZURE_OPENAI_ENDPOINT=<your-azure-openai-endpoint>\n",
    "AZURE_OPENAI_API_KEY=<your-azure-openai-api-key>\n",
    "AZURE_OPENAI_DEPLOYMENT=<your-azure-openai-deployment>\n",
    "AZURE_OPENAI_API_VERSION=<your-azure-openai-api-version>\n",
    "AZURE_SUBSCRIPTION_ID=<your-azure-subscription-id>\n",
    "AZURE_RESOURCE_GROUP=<your-azure-resource-group>\n",
    "AZURE_AI_FOUNDRY_PROJECT=<your-azure-azure_foundry_project>\n",
    "```\n",
    "\n",
    "### References\n",
    "\n",
    "- [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-studio/what-is-ai-studio)\n",
    "- [Evaluate your Generative AI application locally with the Azure AI Evaluation SDK](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/develop/evaluate-sdk#evaluating-direct-and-indirect-attack-jailbreak-vulnerability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff337f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-evaluation in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: notebook in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (7.3.3)\n",
      "Requirement already satisfied: promptflow-azure in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (1.17.2)\n",
      "Requirement already satisfied: azure-identity in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (1.21.0)\n",
      "Requirement already satisfied: openai in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.70.0)\n",
      "Requirement already satisfied: azure-ai-projects in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (1.0.0b8)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (6.29.5)\n",
      "Requirement already satisfied: promptflow in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (1.17.2)\n",
      "Requirement already satisfied: promptflow.core in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from -r requirements.txt (line 9)) (1.17.2)\n",
      "Requirement already satisfied: promptflow-devkit>=1.17.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-evaluation->-r requirements.txt (line 1)) (1.17.2)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-evaluation->-r requirements.txt (line 1)) (2.10.1)\n",
      "Requirement already satisfied: azure-core>=1.30.2 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-evaluation->-r requirements.txt (line 1)) (1.33.0)\n",
      "Requirement already satisfied: nltk>=3.9.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-evaluation->-r requirements.txt (line 1)) (3.9.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-evaluation->-r requirements.txt (line 1)) (12.25.1)\n",
      "Requirement already satisfied: httpx>=0.25.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-evaluation->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.2 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-evaluation->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-evaluation->-r requirements.txt (line 1)) (0.18.10)\n",
      "Requirement already satisfied: msrest>=0.6.21 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-evaluation->-r requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from notebook->-r requirements.txt (line 2)) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from notebook->-r requirements.txt (line 2)) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.4,>=4.3.6 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from notebook->-r requirements.txt (line 2)) (4.3.6)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from notebook->-r requirements.txt (line 2)) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from notebook->-r requirements.txt (line 2)) (6.4.2)\n",
      "Requirement already satisfied: azure-ai-ml<2.0.0,>=1.14.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-azure->-r requirements.txt (line 3)) (1.26.1)\n",
      "Requirement already satisfied: azure-cosmos<5.0.0,>=4.5.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-azure->-r requirements.txt (line 3)) (4.9.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 4)) (44.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 4)) (1.32.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 4)) (4.13.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 5)) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 5)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 5)) (2.11.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-projects->-r requirements.txt (line 6)) (0.7.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (1.8.13)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (8.35.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (6.1.1)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (26.4.0)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (5.14.3)\n",
      "Requirement already satisfied: promptflow-tracing==1.17.2 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow->-r requirements.txt (line 8)) (1.17.2)\n",
      "Requirement already satisfied: docstring_parser in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow.core->-r requirements.txt (line 9)) (0.16)\n",
      "Requirement already satisfied: fastapi<1.0.0,>=0.109.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow.core->-r requirements.txt (line 9)) (0.115.12)\n",
      "Requirement already satisfied: filetype>=1.2.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow.core->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: flask<4.0.0,>=2.2.3 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow.core->-r requirements.txt (line 9)) (3.1.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow.core->-r requirements.txt (line 9)) (4.23.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow.core->-r requirements.txt (line 9)) (2.9.0.post0)\n",
      "Requirement already satisfied: argcomplete>=3.2.3 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (3.6.2)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.0.0b35)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: flask-cors<6.0.0,>=5.0.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (5.0.1)\n",
      "Requirement already satisfied: flask-restx<2.0.0,>=1.2.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (3.1.44)\n",
      "Requirement already satisfied: keyring<25.0.0,>=24.2.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (24.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (3.26.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.31.1)\n",
      "Requirement already satisfied: pillow<11.1.0,>=10.1.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (11.0.0)\n",
      "Requirement already satisfied: pydash<8.0.0,>=6.0.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (7.0.7)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (310)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (2.0.40)\n",
      "Requirement already satisfied: strictyaml<2.0.0,>=1.5.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.7.3)\n",
      "Requirement already satisfied: tabulate<1.0.0,>=0.9.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: waitress<4.0.0,>=3.0.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-tracing==1.17.2->promptflow->-r requirements.txt (line 8)) (1.31.1)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from promptflow-tracing==1.17.2->promptflow->-r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 5)) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: azure-mgmt-core>=1.3.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: azure-storage-file-share in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (12.21.0)\n",
      "Requirement already satisfied: azure-storage-file-datalake>=12.2.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (12.20.0)\n",
      "Requirement already satisfied: azure-common>=1.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (1.1.28)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (1.6.5)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from cryptography>=2.5->azure-identity->-r requirements.txt (line 4)) (1.17.1)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow.core->-r requirements.txt (line 9)) (0.46.1)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow.core->-r requirements.txt (line 9)) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow.core->-r requirements.txt (line 9)) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow.core->-r requirements.txt (line 9)) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow.core->-r requirements.txt (line 9)) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow.core->-r requirements.txt (line 9)) (1.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from httpx>=0.25.1->azure-ai-evaluation->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from httpx>=0.25.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.1->azure-ai-evaluation->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow.core->-r requirements.txt (line 9)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow.core->-r requirements.txt (line 9)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow.core->-r requirements.txt (line 9)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow.core->-r requirements.txt (line 9)) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 7)) (4.3.7)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.21.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (2.0.15)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyterlab<4.4,>=4.3.6->notebook->-r requirements.txt (line 2)) (2.0.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyterlab<4.4,>=4.3.6->notebook->-r requirements.txt (line 2)) (2.2.5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyterlab<4.4,>=4.3.6->notebook->-r requirements.txt (line 2)) (65.5.0)\n",
      "Requirement already satisfied: tomli>=1.2.2 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyterlab<4.4,>=4.3.6->notebook->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->-r requirements.txt (line 2)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->-r requirements.txt (line 2)) (0.12.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from msrest>=0.6.21->azure-ai-evaluation->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation->-r requirements.txt (line 1)) (2.2.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 5)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from ruamel.yaml<1.0.0,>=0.17.10->azure-ai-evaluation->-r requirements.txt (line 1)) (0.2.12)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (21.2.0)\n",
      "Requirement already satisfied: aiohttp>=3.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure->-r requirements.txt (line 3)) (3.11.16)\n",
      "Requirement already satisfied: fixedint==0.1.6 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (0.1.6)\n",
      "Requirement already satisfied: opentelemetry-api~=1.26 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.31.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->-r requirements.txt (line 4)) (2.22)\n",
      "Requirement already satisfied: aniso8601>=0.82 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (10.0.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (6.5.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (4.0.12)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow.core->-r requirements.txt (line 9)) (3.0.2)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.1.1)\n",
      "Requirement already satisfied: jaraco.classes in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.11.4 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (8.6.1)\n",
      "Requirement already satisfied: pywin32-ctypes>=0.2.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.5.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (2.21.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.2.18)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.69.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.31.1)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from opentelemetry-proto==1.31.1->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (5.29.4)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow->-r requirements.txt (line 8)) (0.52b1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-evaluation->-r requirements.txt (line 1)) (3.2.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: azure-core-tracing-opentelemetry~=1.0.0b11 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (1.0.0b12)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-django~=0.49b0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi~=0.49b0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-flask~=0.49b0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-psycopg2~=0.49b0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-requests~=0.49b0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-urllib~=0.49b0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-urllib3~=0.49b0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-resource-detector-azure~=0.1.4 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.1.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from aiohttp>=3.0->azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure->-r requirements.txt (line 3)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from aiohttp>=3.0->azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from aiohttp>=3.0->azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure->-r requirements.txt (line 3)) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from aiohttp>=3.0->azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from aiohttp>=3.0->azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure->-r requirements.txt (line 3)) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from aiohttp>=3.0->azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure->-r requirements.txt (line 3)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from aiohttp>=3.0->azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure->-r requirements.txt (line 3)) (1.19.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (1.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (5.0.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (3.21.0)\n",
      "Requirement already satisfied: fqdn in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (24.11.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-wsgi==0.52b1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.52b1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (3.8.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-dbapi==0.52b1 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-psycopg2~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure->-r requirements.txt (line 3)) (0.52b1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (2.6)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation->-r requirements.txt (line 1)) (10.6.0)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\akaruparti\\documents\\genai-evals\\genai-evals\\.venv\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (2.9.0.20241206)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc35897",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "630cdd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from promptflow.core import AzureOpenAIModelConfiguration\n",
    "from promptflow.tracing import start_trace\n",
    "\n",
    "if \"AZURE_OPENAI_API_KEY\" not in os.environ:\n",
    "    # load environment variables from .env file\n",
    "    load_dotenv()\n",
    "\n",
    "# start a trace session, and print a url for user to check trace\n",
    "start_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03acbd3",
   "metadata": {},
   "source": [
    "## Setup Credentials and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2926c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.getenv(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.getenv(\"AZURE_RESOURCE_GROUP\"),\n",
    "    \"project_name\": os.getenv(\"AZURE_AI_FOUNDRY_PROJECT\"),\n",
    "}\n",
    "\n",
    "\n",
    "model_config = {\n",
    "    \"api_key\":os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"azure_deployment\": os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "configuration = AzureOpenAIModelConfiguration(\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4ccaf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subscription_id': '0debeb64-562c-44d8-9966-110450d5f9ed', 'resource_group_name': 'paramount-data-analytics', 'project_name': 'paramountda01'}\n"
     ]
    }
   ],
   "source": [
    "print(azure_ai_project)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad60c55",
   "metadata": {},
   "source": [
    "## Groundedness Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65ed30e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groundedness': 2.0, 'gpt_groundedness': 2.0, 'groundedness_reason': 'The response is related to the topic of travel exemptions but does not directly address the specific query about apartments for cargo freight. It provides detailed information about interline ticketing and prorate agreements, which is not relevant to the query.', 'groundedness_result': 'fail', 'groundedness_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import GroundednessProEvaluator, GroundednessEvaluator\n",
    "\n",
    "# Initialazing Groundedness and Groundedness Pro evaluators\n",
    "groundedness_eval = GroundednessEvaluator(model_config, threshold=3)\n",
    "\n",
    "query_response_pass = dict(\n",
    "    query=\"are partments for cargo freight exempt under the travel exemption?\",\n",
    "    context=\"\",\n",
    "    response=\"No. According to the exemption language set forth in several of these documents  for example, [31 CFR  545.208] and [31 CFR  536.205]  the travel exemption applies only to transactions \\\"ordinarily incident to travel.\\\" That phrase is defined to include items such as the export or importation of accompanied baggage for personal use, payment of living expenses, and arrangements or facilitation of travel. In contrast, arrangements or transactions related to cargo freight  including any compartments or facilities used solely for the transport of commercial cargo  are not covered by this exemption. In other words, because cargo freight shipments (or \\\"parts\\\" thereof) do not fall into the category of matters incident to personal travel, they do not benefit from the travel exemption provided under these regulations. None of the documents indicate that any commercial cargo freight or compartments used for it are treated as \\\"accompanied baggage\\\" or otherwise incident to travel for personal use. The commentary accompanying these provisions further reinforces that the travel exemption is intended solely for travel-related transactions (whether for accompanied baggage or for travel arrangements), not for the exportation of goods or commercial freight services.\"\n",
    ")\n",
    "\n",
    "query_response_fail = dict(\n",
    "    query=\"are partments for cargo freight exempt under the travel exemption?\",\n",
    "    context=\"\",\n",
    "    response=\"Yes. According to [Case No. IA-16194], U.S. airlines generally may rely on the travel exemption to enter into interline ticketing and baggage (ITB) and special prorate agreements (SPAs) with Iranian airlinesprovided the agreements are directly incident to arranging or facilitating international travel to or from Iran. [Case No. IA-16194] explains that while the Iranian Transactions Regulations impose broad prohibitions on transactions with Iranian goods or services, the exemption in  560.210(d) covers transactions ordinarily incident to travel. In this context, interline ticketing and prorate agreements are considered part of travel arrangements, as long as they are confined to facilitating travel. The guidance in [Case No. IA-16194] also emphasizes that in order to fully determine exemption status, additional details must be provided about the specific nature of the ITB and SPA agreementssuch as whether the agreements include any components (for example, ancillary goods or services) that may fall outside the direct facilitation of travel. Moreover, it is noted that the exemption does not apply to entities designated under the Global Terrorism Sanctions Regulations (GTSR) (see commentary in [Case No. IA-16194]), so if any counterparties are so designated, the exemption would not apply. In summary, for U.S. airlines:  If an interline ticketing and baggage or special prorate agreement is strictly limited to activities directly incident to international travel (e.g., issuing tickets, coordinating baggage transfer, or proration of travel fares), then such transactions are exempt under the travel exemption.  If the agreements include additional nontravel-related components or involve counterparties designated under certain sanctions (such as under the GTSR), then the exemption may not apply. This analysis is based on the information and guidance provided in [Case No. IA-16194].\"\n",
    ")\n",
    "\n",
    "# Running Groundedness Evaluator on a query and response pair\n",
    "groundedness_score = groundedness_eval(\n",
    "    **query_response_fail\n",
    ")\n",
    "print(groundedness_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b8e23aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "      <th>groundedness</th>\n",
       "      <th>groundedness_reason</th>\n",
       "      <th>groundedness_result</th>\n",
       "      <th>groundedness_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>are partments for cargo freight exempt under the travel exemption?</td>\n",
       "      <td>No. According to the exemption language set forth in several of these documents  for example, [31 CFR  545.208] and [31 CFR  536.205]  the travel exemption applies only to transactions \"ordinarily incident to travel.\" That phrase is defined to include items such as the export or importation of accompanied baggage for personal use, payment of living expenses, and arrangements or facilitation of travel. In contrast, arrangements or transactions related to cargo freight  including any compartments or facilities used solely for the transport of commercial cargo  are not covered by this exemption.\\nIn other words, because cargo freight shipments (or parts thereof) do not fall into the category of matters incident to personal travel, they do not benefit from the travel exemption provided under these regulations. None of the documents indicate that any commercial cargo freight or compartments used for it are treated as accompanied baggage or otherwise incident to travel for personal use.\\nThe commentary accompanying these provisions further reinforces that the travel exemption is intended solely for travel-related transactions (whether for accompanied baggage or for travel arrangements), not for the exportation of goods or commercial freight services.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is fully correct and complete, providing a detailed explanation based on specific regulations and directly addressing the query.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>are Interline Ticketing and Baggage and Special Prorate Agreements exempt under the travel exemption?</td>\n",
       "      <td>Yes. According to [Case No. IA-16194], U.S. airlines generally may rely on the travel exemption to enter into interline ticketing and baggage (ITB) and special prorate agreements (SPAs) with Iranian airlinesprovided the agreements are directly incident to arranging or facilitating international travel to or from Iran. [Case No. IA-16194] explains that while the Iranian Transactions Regulations impose broad prohibitions on transactions with Iranian goods or services, the exemption in  560.210(d) covers transactions ordinarily incident to travel. In this context, interline ticketing and prorate agreements are considered part of travel arrangements, as long as they are confined to facilitating travel.\\nThe guidance in [Case No. IA-16194] also emphasizes that to determine exemption status, additional details must be provided about the specific nature of the ITB and SPA agreementssuch as whether the agreements include components that fall outside the direct facilitation of travel. Moreover, the exemption does not apply to entities designated under the Global Terrorism Sanctions Regulations (GTSR).\\nSummary:\\n If the agreement is strictly limited to activities directly incident to travel (ticketing, baggage transfer, fare proration), it is exempt.\\n If it includes non-travel components or involves designated counterparties, it is not.\\nThis analysis is based on [Case No. IA-16194].</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The RESPONSE is fully correct and complete, directly addressing the QUERY with precise information from the CONTEXT.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is paying \"landings fees and ground handling payments\" to a blocked airport operator in connection with a charter flight exempt under the travel exemption?</td>\n",
       "      <td>No. According to [Case No. Ukraine-EO13662-2018-353695-1] and the related discussion in Notable Examples Illustrating the Scope of the IEEPA Travel Exemption, payments for landing fees and ground-handling services to a blocked airport operator are not treated as transactions ordinarily incident to travel and therefore are not covered by the travel exemption.\\nThe case notes that although certain charter-flight operations may be authorized if they lack a U.S. nexus, OFAC did not indicate that the travel exemption applies to fees paid to blocked operators. The cited examples explicitly list such payments as non-exempt.\\nThus, paying landing-fee or ground-handling charges to a blocked airport operator is not exempt under the travel exemption.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is fully correct and complete, providing all relevant details from the context to answer the query accurately.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are transactions related to Information housed on a subscription database of legal information exempt under the informational materials exemption?</td>\n",
       "      <td>Yes. According to [Case No. IA-2012-293259-1], providing access to a subscription database of legal information can be exempt under the informational-materials exemptionprovided the content is fully created and in existence at the time of transmission and is not created or altered at the behest of a sanctioned person. [Case No. MUL-2012-298067-1] further clarifies that commercial subscriptions to pre-existing legal content qualify as exempt if no prohibited alterations occur.\\nIn summary, subscription access to a database of pre-existing legal materials is exempt so long as the materials are not newly created or modified for a sanctioned person.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is fully correct and complete, directly addressing the query with precise information and relevant details from the context.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>would broadcasting an advertisement on behalf of a sanctioned person be allowed under OFAC rules?</td>\n",
       "      <td>Yes. Broadcasting a pre-existing, copy-ready advertisement on behalf of a sanctioned person can fall within the informational-materials exemption. [FAC No. CU-156123] states that a U.S. radio stations dissemination of an unaltered commercial audio tape for a Cuban national was exempt. Related rulings (e.g., 031211-FACRL-IA-14) confirm that if the ad is fully created before transmission and the U.S. broadcaster merely disseminates itwithout creative modification or additional marketing servicesit is exempt. If the broadcaster adds creative or consulting services, a license would be required.\\nThus, mere dissemination of a pre-existing advertisement is generally permitted; additional marketing services are not.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is fully correct and complete, directly addressing the query with precise information and relevant details from the context.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>are sculptures informational materials?</td>\n",
       "      <td>Yes. Under 31 CFR  579.305, artworks classified under HTSUS headings 9701, 9702, or 9703 are informational materials. Sculptures (heading 9703) therefore qualify. [Case No. IA-17159] and the decision in United States v. Three Burmese Statues confirm that original sculptures meet the criteria if fully created at the time of the transaction. Hence, sculptures are informational materials when properly classified.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is fully correct and complete, directly addressing the query with precise information and relevant details.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>would it be prohibited to donate books to north korea?</td>\n",
       "      <td>Generally no. [Case No. DPRK2-2018-356417-1] states that donated books are informational materials under the North Korea Sanctions Regulations, so their export is exempt. However, coordination with North Korean government entities beyond the simple donation may require a specific OFAC license. Donating books alone is not prohibited, but additional engagement with blocked entities is.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is fully correct and complete, addressing the query with precise information and relevant details about the regulations and potential requirements for donating books to North Korea.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>can iranian origin banknotes be imported into the U.S?</td>\n",
       "      <td>It depends. [Case No. IA-2018-355540-1] explains that importation of Iranian-origin goods is generally prohibited, but demonetized (no-longer-valid) banknotes may qualify as informational materials. Importation or exportation of such demonetized notes can be exempt. If the notes are still valid currency, or if the transaction is wholly domestic within the U.S., a specific license is required. Thus, only demonetized notes moved across borders under the informational-materials exemption can be imported without a license; valid currency or purely domestic transactions require OFAC authorization.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is fully correct and complete, providing all necessary details about the conditions for importing Iranian-origin banknotes into the U.S.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                         query  \\\n",
       "0                                                                                           are partments for cargo freight exempt under the travel exemption?   \n",
       "1                                                        are Interline Ticketing and Baggage and Special Prorate Agreements exempt under the travel exemption?   \n",
       "2  Is paying \"landings fees and ground handling payments\" to a blocked airport operator in connection with a charter flight exempt under the travel exemption?   \n",
       "3           are transactions related to Information housed on a subscription database of legal information exempt under the informational materials exemption?   \n",
       "4                                                            would broadcasting an advertisement on behalf of a sanctioned person be allowed under OFAC rules?   \n",
       "5                                                                                                                      are sculptures informational materials?   \n",
       "6                                                                                                       would it be prohibited to donate books to north korea?   \n",
       "7                                                                                                       can iranian origin banknotes be imported into the U.S?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      response  \\\n",
       "0                                                                                                                                   No. According to the exemption language set forth in several of these documents  for example, [31 CFR  545.208] and [31 CFR  536.205]  the travel exemption applies only to transactions \"ordinarily incident to travel.\" That phrase is defined to include items such as the export or importation of accompanied baggage for personal use, payment of living expenses, and arrangements or facilitation of travel. In contrast, arrangements or transactions related to cargo freight  including any compartments or facilities used solely for the transport of commercial cargo  are not covered by this exemption.\\nIn other words, because cargo freight shipments (or parts thereof) do not fall into the category of matters incident to personal travel, they do not benefit from the travel exemption provided under these regulations. None of the documents indicate that any commercial cargo freight or compartments used for it are treated as accompanied baggage or otherwise incident to travel for personal use.\\nThe commentary accompanying these provisions further reinforces that the travel exemption is intended solely for travel-related transactions (whether for accompanied baggage or for travel arrangements), not for the exportation of goods or commercial freight services.   \n",
       "1  Yes. According to [Case No. IA-16194], U.S. airlines generally may rely on the travel exemption to enter into interline ticketing and baggage (ITB) and special prorate agreements (SPAs) with Iranian airlinesprovided the agreements are directly incident to arranging or facilitating international travel to or from Iran. [Case No. IA-16194] explains that while the Iranian Transactions Regulations impose broad prohibitions on transactions with Iranian goods or services, the exemption in  560.210(d) covers transactions ordinarily incident to travel. In this context, interline ticketing and prorate agreements are considered part of travel arrangements, as long as they are confined to facilitating travel.\\nThe guidance in [Case No. IA-16194] also emphasizes that to determine exemption status, additional details must be provided about the specific nature of the ITB and SPA agreementssuch as whether the agreements include components that fall outside the direct facilitation of travel. Moreover, the exemption does not apply to entities designated under the Global Terrorism Sanctions Regulations (GTSR).\\nSummary:\\n If the agreement is strictly limited to activities directly incident to travel (ticketing, baggage transfer, fare proration), it is exempt.\\n If it includes non-travel components or involves designated counterparties, it is not.\\nThis analysis is based on [Case No. IA-16194].   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            No. According to [Case No. Ukraine-EO13662-2018-353695-1] and the related discussion in Notable Examples Illustrating the Scope of the IEEPA Travel Exemption, payments for landing fees and ground-handling services to a blocked airport operator are not treated as transactions ordinarily incident to travel and therefore are not covered by the travel exemption.\\nThe case notes that although certain charter-flight operations may be authorized if they lack a U.S. nexus, OFAC did not indicate that the travel exemption applies to fees paid to blocked operators. The cited examples explicitly list such payments as non-exempt.\\nThus, paying landing-fee or ground-handling charges to a blocked airport operator is not exempt under the travel exemption.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Yes. According to [Case No. IA-2012-293259-1], providing access to a subscription database of legal information can be exempt under the informational-materials exemptionprovided the content is fully created and in existence at the time of transmission and is not created or altered at the behest of a sanctioned person. [Case No. MUL-2012-298067-1] further clarifies that commercial subscriptions to pre-existing legal content qualify as exempt if no prohibited alterations occur.\\nIn summary, subscription access to a database of pre-existing legal materials is exempt so long as the materials are not newly created or modified for a sanctioned person.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Yes. Broadcasting a pre-existing, copy-ready advertisement on behalf of a sanctioned person can fall within the informational-materials exemption. [FAC No. CU-156123] states that a U.S. radio stations dissemination of an unaltered commercial audio tape for a Cuban national was exempt. Related rulings (e.g., 031211-FACRL-IA-14) confirm that if the ad is fully created before transmission and the U.S. broadcaster merely disseminates itwithout creative modification or additional marketing servicesit is exempt. If the broadcaster adds creative or consulting services, a license would be required.\\nThus, mere dissemination of a pre-existing advertisement is generally permitted; additional marketing services are not.   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Yes. Under 31 CFR  579.305, artworks classified under HTSUS headings 9701, 9702, or 9703 are informational materials. Sculptures (heading 9703) therefore qualify. [Case No. IA-17159] and the decision in United States v. Three Burmese Statues confirm that original sculptures meet the criteria if fully created at the time of the transaction. Hence, sculptures are informational materials when properly classified.   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Generally no. [Case No. DPRK2-2018-356417-1] states that donated books are informational materials under the North Korea Sanctions Regulations, so their export is exempt. However, coordination with North Korean government entities beyond the simple donation may require a specific OFAC license. Donating books alone is not prohibited, but additional engagement with blocked entities is.   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      It depends. [Case No. IA-2018-355540-1] explains that importation of Iranian-origin goods is generally prohibited, but demonetized (no-longer-valid) banknotes may qualify as informational materials. Importation or exportation of such demonetized notes can be exempt. If the notes are still valid currency, or if the transaction is wholly domestic within the U.S., a specific license is required. Thus, only demonetized notes moved across borders under the informational-materials exemption can be imported without a license; valid currency or purely domestic transactions require OFAC authorization.   \n",
       "\n",
       "   groundedness  \\\n",
       "0           5.0   \n",
       "1           5.0   \n",
       "2           5.0   \n",
       "3           5.0   \n",
       "4           5.0   \n",
       "5           5.0   \n",
       "6           5.0   \n",
       "7           5.0   \n",
       "\n",
       "                                                                                                                                                                                  groundedness_reason  \\\n",
       "0                                                       The response is fully correct and complete, providing a detailed explanation based on specific regulations and directly addressing the query.   \n",
       "1                                                                                The RESPONSE is fully correct and complete, directly addressing the QUERY with precise information from the CONTEXT.   \n",
       "2                                                                         The response is fully correct and complete, providing all relevant details from the context to answer the query accurately.   \n",
       "3                                                           The response is fully correct and complete, directly addressing the query with precise information and relevant details from the context.   \n",
       "4                                                           The response is fully correct and complete, directly addressing the query with precise information and relevant details from the context.   \n",
       "5                                                                            The response is fully correct and complete, directly addressing the query with precise information and relevant details.   \n",
       "6  The response is fully correct and complete, addressing the query with precise information and relevant details about the regulations and potential requirements for donating books to North Korea.   \n",
       "7                                               The response is fully correct and complete, providing all necessary details about the conditions for importing Iranian-origin banknotes into the U.S.   \n",
       "\n",
       "  groundedness_result  groundedness_threshold  \n",
       "0                pass                       3  \n",
       "1                pass                       3  \n",
       "2                pass                       3  \n",
       "3                pass                       3  \n",
       "4                pass                       3  \n",
       "5                pass                       3  \n",
       "6                pass                       3  \n",
       "7                pass                       3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "records = []\n",
    "with open(\"data/data.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        result = groundedness_eval(\n",
    "            query=item[\"query\"],\n",
    "            context=item.get(\"context\", \"\"),\n",
    "            response=item[\"ground_truth\"]\n",
    "        )\n",
    "        records.append({\n",
    "            \"query\": item[\"query\"],\n",
    "            \"response\": item[\"ground_truth\"],\n",
    "            \"groundedness\": result[\"groundedness\"],\n",
    "            \"groundedness_reason\": result[\"groundedness_reason\"],\n",
    "            \"groundedness_result\": result[\"groundedness_result\"],\n",
    "            \"groundedness_threshold\": result[\"groundedness_threshold\"],\n",
    "        })\n",
    "\n",
    "# Load into a DataFrame and display\n",
    "df = pd.DataFrame(records)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8753b1",
   "metadata": {},
   "source": [
    "## Relevance Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "960b3e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 4.0, 'gpt_relevance': 4.0, 'relevance_reason': 'The RESPONSE fully addresses the QUERY with accurate and complete information, including references to specific regulations and a detailed explanation of why cargo freight is not exempt under the travel exemption.', 'relevance_result': 'pass', 'relevance_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import RelevanceEvaluator\n",
    "\n",
    "# Initialazing Groundedness and Groundedness Pro evaluators\n",
    "relevance_eval = RelevanceEvaluator(model_config, threshold=3)\n",
    "\n",
    "query_response = dict(\n",
    "    query=\"are partments for cargo freight exempt under the travel exemption?\",\n",
    "    context=\"\",\n",
    "    response=\"No. According to the exemption language set forth in several of these documents  for example, [31 CFR  545.208] and [31 CFR  536.205]  the travel exemption applies only to transactions \\\"ordinarily incident to travel.\\\" That phrase is defined to include items such as the export or importation of accompanied baggage for personal use, payment of living expenses, and arrangements or facilitation of travel. In contrast, arrangements or transactions related to cargo freight  including any compartments or facilities used solely for the transport of commercial cargo  are not covered by this exemption.In other words, because cargo freight shipments (or parts thereof) do not fall into the category of matters incident to personal travel, they do not benefit from the travel exemption provided under these regulations. None of the documents indicate that any commercial cargo freight or compartments used for it are treated as accompanied baggage or otherwise incident to travel for personal use.The commentary accompanying these provisions further reinforces that the travel exemption is intended solely for travel-related transactions (whether for accompanied baggage or for travel arrangements), not for the exportation of goods or commercial freight services..\"\n",
    ")\n",
    "\n",
    "query_response_fail = dict(\n",
    "    query=\"are partments for cargo freight exempt under the travel exemption?\",\n",
    "    context=\"\",\n",
    "    response=\"Yes. According to [Case No. IA-16194], U.S. airlines generally may rely on the travel exemption to enter into interline ticketing and baggage (ITB) and special prorate agreements (SPAs) with Iranian airlinesprovided the agreements are directly incident to arranging or facilitating international travel to or from Iran. [Case No. IA-16194] explains that while the Iranian Transactions Regulations impose broad prohibitions on transactions with Iranian goods or services, the exemption in  560.210(d) covers transactions ordinarily incident to travel. In this context, interline ticketing and prorate agreements are considered part of travel arrangements, as long as they are confined to facilitating travel. The guidance in [Case No. IA-16194] also emphasizes that in order to fully determine exemption status, additional details must be provided about the specific nature of the ITB and SPA agreementssuch as whether the agreements include any components (for example, ancillary goods or services) that may fall outside the direct facilitation of travel. Moreover, it is noted that the exemption does not apply to entities designated under the Global Terrorism Sanctions Regulations (GTSR) (see commentary in [Case No. IA-16194]), so if any counterparties are so designated, the exemption would not apply. In summary, for U.S. airlines:  If an interline ticketing and baggage or special prorate agreement is strictly limited to activities directly incident to international travel (e.g., issuing tickets, coordinating baggage transfer, or proration of travel fares), then such transactions are exempt under the travel exemption.  If the agreements include additional nontravel-related components or involve counterparties designated under certain sanctions (such as under the GTSR), then the exemption may not apply. This analysis is based on the information and guidance provided in [Case No. IA-16194].\"\n",
    ")\n",
    "\n",
    "\n",
    "# Running Groundedness Evaluator on a query and response pair\n",
    "relevance_eval_score = relevance_eval(\n",
    "    **query_response_pass\n",
    ")\n",
    "print(relevance_eval_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09b82166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevant_reason</th>\n",
       "      <th>relevant_result</th>\n",
       "      <th>relevant_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>are partments for cargo freight exempt under the travel exemption?</td>\n",
       "      <td>No. According to the exemption language set forth in several of these documents  for example, [31 CFR  545.208] and [31 CFR  536.205]  the travel exemption applies only to transactions \"ordinarily incident to travel.\" That phrase is defined to include items such as the export or importation of accompanied baggage for personal use, payment of living expenses, and arrangements or facilitation of travel. In contrast, arrangements or transactions related to cargo freight  including any compartments or facilities used solely for the transport of commercial cargo  are not covered by this exemption.\\nIn other words, because cargo freight shipments (or parts thereof) do not fall into the category of matters incident to personal travel, they do not benefit from the travel exemption provided under these regulations. None of the documents indicate that any commercial cargo freight or compartments used for it are treated as accompanied baggage or otherwise incident to travel for personal use.\\nThe commentary accompanying these provisions further reinforces that the travel exemption is intended solely for travel-related transactions (whether for accompanied baggage or for travel arrangements), not for the exportation of goods or commercial freight services.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with accurate and complete information, explaining why cargo freight compartments are not exempt under the travel exemption. It includes all essential details required for a comprehensive understanding.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>are Interline Ticketing and Baggage and Special Prorate Agreements exempt under the travel exemption?</td>\n",
       "      <td>Yes. According to [Case No. IA-16194], U.S. airlines generally may rely on the travel exemption to enter into interline ticketing and baggage (ITB) and special prorate agreements (SPAs) with Iranian airlinesprovided the agreements are directly incident to arranging or facilitating international travel to or from Iran. [Case No. IA-16194] explains that while the Iranian Transactions Regulations impose broad prohibitions on transactions with Iranian goods or services, the exemption in  560.210(d) covers transactions ordinarily incident to travel. In this context, interline ticketing and prorate agreements are considered part of travel arrangements, as long as they are confined to facilitating travel.\\nThe guidance in [Case No. IA-16194] also emphasizes that to determine exemption status, additional details must be provided about the specific nature of the ITB and SPA agreementssuch as whether the agreements include components that fall outside the direct facilitation of travel. Moreover, the exemption does not apply to entities designated under the Global Terrorism Sanctions Regulations (GTSR).\\nSummary:\\n If the agreement is strictly limited to activities directly incident to travel (ticketing, baggage transfer, fare proration), it is exempt.\\n If it includes non-travel components or involves designated counterparties, it is not.\\nThis analysis is based on [Case No. IA-16194].</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with accurate and complete information, including relevant insights and conditions for the exemption.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is paying \"landings fees and ground handling payments\" to a blocked airport operator in connection with a charter flight exempt under the travel exemption?</td>\n",
       "      <td>No. According to [Case No. Ukraine-EO13662-2018-353695-1] and the related discussion in Notable Examples Illustrating the Scope of the IEEPA Travel Exemption, payments for landing fees and ground-handling services to a blocked airport operator are not treated as transactions ordinarily incident to travel and therefore are not covered by the travel exemption.\\nThe case notes that although certain charter-flight operations may be authorized if they lack a U.S. nexus, OFAC did not indicate that the travel exemption applies to fees paid to blocked operators. The cited examples explicitly list such payments as non-exempt.\\nThus, paying landing-fee or ground-handling charges to a blocked airport operator is not exempt under the travel exemption.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with accurate and complete information, including relevant examples and case references, making it a comprehensive response.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are transactions related to Information housed on a subscription database of legal information exempt under the informational materials exemption?</td>\n",
       "      <td>Yes. According to [Case No. IA-2012-293259-1], providing access to a subscription database of legal information can be exempt under the informational-materials exemptionprovided the content is fully created and in existence at the time of transmission and is not created or altered at the behest of a sanctioned person. [Case No. MUL-2012-298067-1] further clarifies that commercial subscriptions to pre-existing legal content qualify as exempt if no prohibited alterations occur.\\nIn summary, subscription access to a database of pre-existing legal materials is exempt so long as the materials are not newly created or modified for a sanctioned person.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with accurate and complete information, including specific case references and a summary of the conditions for exemption. It provides all essential details required for a comprehensive understanding.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>would broadcasting an advertisement on behalf of a sanctioned person be allowed under OFAC rules?</td>\n",
       "      <td>Yes. Broadcasting a pre-existing, copy-ready advertisement on behalf of a sanctioned person can fall within the informational-materials exemption. [FAC No. CU-156123] states that a U.S. radio stations dissemination of an unaltered commercial audio tape for a Cuban national was exempt. Related rulings (e.g., 031211-FACRL-IA-14) confirm that if the ad is fully created before transmission and the U.S. broadcaster merely disseminates itwithout creative modification or additional marketing servicesit is exempt. If the broadcaster adds creative or consulting services, a license would be required.\\nThus, mere dissemination of a pre-existing advertisement is generally permitted; additional marketing services are not.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with accurate and complete information, including relevant examples and conditions. It also provides additional insights into related rulings and the implications of adding creative or consulting services.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>are sculptures informational materials?</td>\n",
       "      <td>Yes. Under 31 CFR  579.305, artworks classified under HTSUS headings 9701, 9702, or 9703 are informational materials. Sculptures (heading 9703) therefore qualify. [Case No. IA-17159] and the decision in United States v. Three Burmese Statues confirm that original sculptures meet the criteria if fully created at the time of the transaction. Hence, sculptures are informational materials when properly classified.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with accurate and complete information, including legal references and case law to support the classification of sculptures as informational materials.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>would it be prohibited to donate books to north korea?</td>\n",
       "      <td>Generally no. [Case No. DPRK2-2018-356417-1] states that donated books are informational materials under the North Korea Sanctions Regulations, so their export is exempt. However, coordination with North Korean government entities beyond the simple donation may require a specific OFAC license. Donating books alone is not prohibited, but additional engagement with blocked entities is.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with accurate and complete information, and it also includes additional relevant insights about the need for an OFAC license for further engagement.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>can iranian origin banknotes be imported into the U.S?</td>\n",
       "      <td>It depends. [Case No. IA-2018-355540-1] explains that importation of Iranian-origin goods is generally prohibited, but demonetized (no-longer-valid) banknotes may qualify as informational materials. Importation or exportation of such demonetized notes can be exempt. If the notes are still valid currency, or if the transaction is wholly domestic within the U.S., a specific license is required. Thus, only demonetized notes moved across borders under the informational-materials exemption can be imported without a license; valid currency or purely domestic transactions require OFAC authorization.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with accurate and complete information, explaining the conditions and requirements for importing Iranian-origin banknotes into the U.S.</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                         query  \\\n",
       "0                                                                                           are partments for cargo freight exempt under the travel exemption?   \n",
       "1                                                        are Interline Ticketing and Baggage and Special Prorate Agreements exempt under the travel exemption?   \n",
       "2  Is paying \"landings fees and ground handling payments\" to a blocked airport operator in connection with a charter flight exempt under the travel exemption?   \n",
       "3           are transactions related to Information housed on a subscription database of legal information exempt under the informational materials exemption?   \n",
       "4                                                            would broadcasting an advertisement on behalf of a sanctioned person be allowed under OFAC rules?   \n",
       "5                                                                                                                      are sculptures informational materials?   \n",
       "6                                                                                                       would it be prohibited to donate books to north korea?   \n",
       "7                                                                                                       can iranian origin banknotes be imported into the U.S?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      response  \\\n",
       "0                                                                                                                                   No. According to the exemption language set forth in several of these documents  for example, [31 CFR  545.208] and [31 CFR  536.205]  the travel exemption applies only to transactions \"ordinarily incident to travel.\" That phrase is defined to include items such as the export or importation of accompanied baggage for personal use, payment of living expenses, and arrangements or facilitation of travel. In contrast, arrangements or transactions related to cargo freight  including any compartments or facilities used solely for the transport of commercial cargo  are not covered by this exemption.\\nIn other words, because cargo freight shipments (or parts thereof) do not fall into the category of matters incident to personal travel, they do not benefit from the travel exemption provided under these regulations. None of the documents indicate that any commercial cargo freight or compartments used for it are treated as accompanied baggage or otherwise incident to travel for personal use.\\nThe commentary accompanying these provisions further reinforces that the travel exemption is intended solely for travel-related transactions (whether for accompanied baggage or for travel arrangements), not for the exportation of goods or commercial freight services.   \n",
       "1  Yes. According to [Case No. IA-16194], U.S. airlines generally may rely on the travel exemption to enter into interline ticketing and baggage (ITB) and special prorate agreements (SPAs) with Iranian airlinesprovided the agreements are directly incident to arranging or facilitating international travel to or from Iran. [Case No. IA-16194] explains that while the Iranian Transactions Regulations impose broad prohibitions on transactions with Iranian goods or services, the exemption in  560.210(d) covers transactions ordinarily incident to travel. In this context, interline ticketing and prorate agreements are considered part of travel arrangements, as long as they are confined to facilitating travel.\\nThe guidance in [Case No. IA-16194] also emphasizes that to determine exemption status, additional details must be provided about the specific nature of the ITB and SPA agreementssuch as whether the agreements include components that fall outside the direct facilitation of travel. Moreover, the exemption does not apply to entities designated under the Global Terrorism Sanctions Regulations (GTSR).\\nSummary:\\n If the agreement is strictly limited to activities directly incident to travel (ticketing, baggage transfer, fare proration), it is exempt.\\n If it includes non-travel components or involves designated counterparties, it is not.\\nThis analysis is based on [Case No. IA-16194].   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            No. According to [Case No. Ukraine-EO13662-2018-353695-1] and the related discussion in Notable Examples Illustrating the Scope of the IEEPA Travel Exemption, payments for landing fees and ground-handling services to a blocked airport operator are not treated as transactions ordinarily incident to travel and therefore are not covered by the travel exemption.\\nThe case notes that although certain charter-flight operations may be authorized if they lack a U.S. nexus, OFAC did not indicate that the travel exemption applies to fees paid to blocked operators. The cited examples explicitly list such payments as non-exempt.\\nThus, paying landing-fee or ground-handling charges to a blocked airport operator is not exempt under the travel exemption.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Yes. According to [Case No. IA-2012-293259-1], providing access to a subscription database of legal information can be exempt under the informational-materials exemptionprovided the content is fully created and in existence at the time of transmission and is not created or altered at the behest of a sanctioned person. [Case No. MUL-2012-298067-1] further clarifies that commercial subscriptions to pre-existing legal content qualify as exempt if no prohibited alterations occur.\\nIn summary, subscription access to a database of pre-existing legal materials is exempt so long as the materials are not newly created or modified for a sanctioned person.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Yes. Broadcasting a pre-existing, copy-ready advertisement on behalf of a sanctioned person can fall within the informational-materials exemption. [FAC No. CU-156123] states that a U.S. radio stations dissemination of an unaltered commercial audio tape for a Cuban national was exempt. Related rulings (e.g., 031211-FACRL-IA-14) confirm that if the ad is fully created before transmission and the U.S. broadcaster merely disseminates itwithout creative modification or additional marketing servicesit is exempt. If the broadcaster adds creative or consulting services, a license would be required.\\nThus, mere dissemination of a pre-existing advertisement is generally permitted; additional marketing services are not.   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Yes. Under 31 CFR  579.305, artworks classified under HTSUS headings 9701, 9702, or 9703 are informational materials. Sculptures (heading 9703) therefore qualify. [Case No. IA-17159] and the decision in United States v. Three Burmese Statues confirm that original sculptures meet the criteria if fully created at the time of the transaction. Hence, sculptures are informational materials when properly classified.   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Generally no. [Case No. DPRK2-2018-356417-1] states that donated books are informational materials under the North Korea Sanctions Regulations, so their export is exempt. However, coordination with North Korean government entities beyond the simple donation may require a specific OFAC license. Donating books alone is not prohibited, but additional engagement with blocked entities is.   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      It depends. [Case No. IA-2018-355540-1] explains that importation of Iranian-origin goods is generally prohibited, but demonetized (no-longer-valid) banknotes may qualify as informational materials. Importation or exportation of such demonetized notes can be exempt. If the notes are still valid currency, or if the transaction is wholly domestic within the U.S., a specific license is required. Thus, only demonetized notes moved across borders under the informational-materials exemption can be imported without a license; valid currency or purely domestic transactions require OFAC authorization.   \n",
       "\n",
       "   relevance  \\\n",
       "0        4.0   \n",
       "1        5.0   \n",
       "2        5.0   \n",
       "3        4.0   \n",
       "4        5.0   \n",
       "5        4.0   \n",
       "6        5.0   \n",
       "7        4.0   \n",
       "\n",
       "                                                                                                                                                                                                                                        relevant_reason  \\\n",
       "0     The RESPONSE fully addresses the QUERY with accurate and complete information, explaining why cargo freight compartments are not exempt under the travel exemption. It includes all essential details required for a comprehensive understanding.   \n",
       "1                                                                                                          The RESPONSE fully addresses the QUERY with accurate and complete information, including relevant insights and conditions for the exemption.   \n",
       "2                                                                                   The RESPONSE fully addresses the QUERY with accurate and complete information, including relevant examples and case references, making it a comprehensive response.   \n",
       "3        The RESPONSE fully addresses the QUERY with accurate and complete information, including specific case references and a summary of the conditions for exemption. It provides all essential details required for a comprehensive understanding.   \n",
       "4  The RESPONSE fully addresses the QUERY with accurate and complete information, including relevant examples and conditions. It also provides additional insights into related rulings and the implications of adding creative or consulting services.   \n",
       "5                                                        The RESPONSE fully addresses the QUERY with accurate and complete information, including legal references and case law to support the classification of sculptures as informational materials.   \n",
       "6                                                           The RESPONSE fully addresses the QUERY with accurate and complete information, and it also includes additional relevant insights about the need for an OFAC license for further engagement.   \n",
       "7                                                                        The RESPONSE fully addresses the QUERY with accurate and complete information, explaining the conditions and requirements for importing Iranian-origin banknotes into the U.S.   \n",
       "\n",
       "  relevant_result  relevant_threshold  \n",
       "0            pass                   3  \n",
       "1            pass                   3  \n",
       "2            pass                   3  \n",
       "3            pass                   3  \n",
       "4            pass                   3  \n",
       "5            pass                   3  \n",
       "6            pass                   3  \n",
       "7            pass                   3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "records = []\n",
    "with open(\"data/data.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        result = relevance_eval(\n",
    "            query=item[\"query\"],\n",
    "            context=item.get(\"context\", \"\"),\n",
    "            response=item[\"ground_truth\"]\n",
    "        )\n",
    "        records.append({\n",
    "            \"query\":       item[\"query\"],\n",
    "            \"response\":    item[\"ground_truth\"],\n",
    "            \"relevance\":   result[\"relevance\"],\n",
    "            \"relevant_reason\": result[\"relevance_reason\"],\n",
    "            \"relevant_result\": result[\"relevance_result\"],\n",
    "            \"relevant_threshold\": result[\"relevance_threshold\"],\n",
    "         \n",
    "        })\n",
    "\n",
    "# 3. Load into a DataFrame and display\n",
    "df = pd.DataFrame(records)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friendliness Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 1, 'reason': 'The response is defensive and lacks warmth or approachability.'}\n"
     ]
    }
   ],
   "source": [
    "from friendliness.friendliness import FriendlinessEvaluator\n",
    "\n",
    "friendliness_eval = FriendlinessEvaluator(configuration)\n",
    "\n",
    "friendliness_score = friendliness_eval(response=\"I will not apologize for my behavior!\")\n",
    "print(friendliness_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a2808a",
   "metadata": {},
   "source": [
    "## Evaluate with both built-in and custom evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e56ff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azure.ai.evaluation._common._experimental:Class ContentSafetyEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "WARNING:azure.ai.evaluation._common._experimental:Class ViolenceEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "WARNING:azure.ai.evaluation._common._experimental:Class SexualEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "WARNING:azure.ai.evaluation._common._experimental:Class SelfHarmEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "WARNING:azure.ai.evaluation._common._experimental:Class HateUnfairnessEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals/data.jsonl\n",
      "{'api_key': 'e058bda1c87b4de297a562abe6439ccb', 'azure_endpoint': 'https://paramountda2801552698.openai.azure.com/', 'azure_deployment': 'gpt-4o', 'type': 'azure_openai', 'api_version': '2024-02-15-preview'}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'groundedness_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 34\u001b[0m\n\u001b[0;32m     24\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(pathlib\u001b[38;5;241m.\u001b[39mPath(pathlib\u001b[38;5;241m.\u001b[39mPath\u001b[38;5;241m.\u001b[39mcwd())) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(path)\n\u001b[0;32m     28\u001b[0m results \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[0;32m     29\u001b[0m     evaluation_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval-Run-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazure_deployment\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtitle(),\n\u001b[0;32m     30\u001b[0m     data\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/data.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     31\u001b[0m     target\u001b[38;5;241m=\u001b[39mModelEndpoint(model_config),\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m     evaluators\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m---> 34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroundedness\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mgroundedness_eval\u001b[49m,\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_safety\u001b[39m\u001b[38;5;124m\"\u001b[39m: content_safety_evaluator,\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoherence\u001b[39m\u001b[38;5;124m\"\u001b[39m: coherence_evaluator,\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelevance\u001b[39m\u001b[38;5;124m\"\u001b[39m: relevance_evaluator,\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroundedness\u001b[39m\u001b[38;5;124m\"\u001b[39m: groundedness_evaluator,\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfluency\u001b[39m\u001b[38;5;124m\"\u001b[39m: fluency_evaluator,\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m: similarity_evaluator,\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfriendliness\u001b[39m\u001b[38;5;124m\"\u001b[39m: friendliness_eval \u001b[38;5;66;03m#custom evaluator\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     },\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# column mapping\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     evaluator_config\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_safety\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.query}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{target.response}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoherence\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{target.response}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.query}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelevance\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     48\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{target.response}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.context}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.query}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     49\u001b[0m         },\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroundedness\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     51\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     52\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{target.response}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     53\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.context}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.query}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m             }\n\u001b[0;32m     56\u001b[0m         },\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfluency\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     58\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{target.response}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.context}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.query}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     59\u001b[0m         },\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     61\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{target.response}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.context}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.query}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     62\u001b[0m         },\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfriendliness\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{target.response}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.context}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.query}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m             }\n\u001b[0;32m     66\u001b[0m         }\n\u001b[0;32m     67\u001b[0m     },\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Optionally provide your Azure AI project information to track your evaluation results in your Azure AI project\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     azure_ai_project \u001b[38;5;241m=\u001b[39m azure_ai_project,\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# # Optionally provide an output path to dump a json of metric summary, row level data and metric and Azure AI project URL\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m \n\u001b[0;32m     73\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'groundedness_eval' is not defined"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "from azure.ai.evaluation import GroundednessProEvaluator, GroundednessEvaluator\n",
    "\n",
    "\n",
    "from azure.ai.evaluation import evaluate\n",
    "from azure.ai.evaluation import (\n",
    "    ContentSafetyEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    CoherenceEvaluator,\n",
    "    GroundednessEvaluator,\n",
    "    FluencyEvaluator,\n",
    "    SimilarityEvaluator,\n",
    ")\n",
    "from model_endpoint import ModelEndpoint\n",
    "\n",
    "\n",
    "content_safety_evaluator = ContentSafetyEvaluator(\n",
    "    azure_ai_project=azure_ai_project, credential=DefaultAzureCredential()\n",
    ")\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "coherence_evaluator = CoherenceEvaluator(model_config)\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
    "fluency_evaluator = FluencyEvaluator(model_config)\n",
    "similarity_evaluator = SimilarityEvaluator(model_config)\n",
    "\n",
    "path = str(pathlib.Path(pathlib.Path.cwd())) + \"/data.jsonl\"\n",
    "\n",
    "print(path)\n",
    "\n",
    "results = evaluate(\n",
    "    evaluation_name=\"Eval-Run-\" + \"-\" + model_config[\"azure_deployment\"].title(),\n",
    "    data= \"./data/data.jsonl\",\n",
    "    target=ModelEndpoint(model_config),\n",
    "\n",
    "    evaluators={\n",
    "        \"groundedness\": groundedness_eval,\n",
    "        \"content_safety\": content_safety_evaluator,\n",
    "        \"coherence\": coherence_evaluator,\n",
    "        \"relevance\": relevance_evaluator,\n",
    "        \"groundedness\": groundedness_evaluator,\n",
    "        \"fluency\": fluency_evaluator,\n",
    "        \"similarity\": similarity_evaluator,\n",
    "        \"friendliness\": friendliness_eval #custom evaluator\n",
    "    },\n",
    "    # column mapping\n",
    "    evaluator_config={\n",
    "        \"content_safety\": {\"column_mapping\": {\"query\": \"${data.query}\", \"response\": \"${target.response}\"}},\n",
    "        \"coherence\": {\"column_mapping\": {\"response\": \"${target.response}\", \"query\": \"${data.query}\"}},\n",
    "        \"relevance\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"groundedness\": {\n",
    "            \"column_mapping\": {\n",
    "                \"response\": \"${target.response}\",\n",
    "                \"context\": \"${data.context}\",\n",
    "                \"query\": \"${data.query}\",\n",
    "            }\n",
    "        },\n",
    "        \"fluency\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"similarity\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"friendliness\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # Optionally provide your Azure AI project information to track your evaluation results in your Azure AI project\n",
    "    azure_ai_project = azure_ai_project,\n",
    "    # # Optionally provide an output path to dump a json of metric summary, row level data and metric and Azure AI project URL\n",
    "    output_path=\"./results.jsonl\"\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96c3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-16 16:24:21 -0400][promptflow][WARNING] - Found existing c:/Users/akaruparti/OneDrive - Microsoft/Documents/Code With/Akin Gump/evals/flow.flex.yaml, will not respect it in runtime.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals/data__2.jsonl\n",
      "{'api_key': 'e058bda1c87b4de297a562abe6439ccb', 'azure_endpoint': 'https://paramountda2801552698.openai.azure.com/', 'azure_deployment': 'gpt-4o', 'type': 'azure_openai', 'api_version': '2024-02-15-preview'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-16 16:25:23 -0400][promptflow._core.entry_meta_generator][WARNING] - Generate meta timeout after 60 seconds, terminate the process.\n",
      "[2025-06-16 16:25:23 -0400][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_None_20250616_162421_520056, log path: C:\\Users\\akaruparti\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_None_20250616_162421_520056\\logs.txt\n"
     ]
    },
    {
     "ename": "EvaluationException",
     "evalue": "(InternalError) [('C:/Users/akaruparti/OneDrive - Microsoft/Documents/Code With/Akin Gump/evals\\\\results.jsonl', 'C:\\\\Users\\\\akaruparti\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_None_20250616_162421_520056\\\\snapshot\\\\results.jsonl', \"[Errno 2] No such file or directory: 'C:/Users/akaruparti/OneDrive - Microsoft/Documents/Code With/Akin Gump/evals\\\\\\\\results.jsonl'\")]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\azure\\ai\\evaluation\\_evaluate\\_evaluate.py:678\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(data, evaluators, evaluation_name, target, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, **kwargs)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 678\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate(\n\u001b[0;32m    679\u001b[0m         evaluation_name\u001b[38;5;241m=\u001b[39mevaluation_name,\n\u001b[0;32m    680\u001b[0m         target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m    681\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m    682\u001b[0m         evaluators\u001b[38;5;241m=\u001b[39mevaluators,\n\u001b[0;32m    683\u001b[0m         evaluator_config\u001b[38;5;241m=\u001b[39mevaluator_config,\n\u001b[0;32m    684\u001b[0m         azure_ai_project\u001b[38;5;241m=\u001b[39mazure_ai_project,\n\u001b[0;32m    685\u001b[0m         output_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[0;32m    686\u001b[0m         fail_on_evaluator_errors\u001b[38;5;241m=\u001b[39mfail_on_evaluator_errors,\n\u001b[0;32m    687\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    688\u001b[0m     )\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;66;03m# Handle multiprocess bootstrap error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\azure\\ai\\evaluation\\_evaluate\\_evaluate.py:791\u001b[0m, in \u001b[0;36m_evaluate\u001b[1;34m(evaluators, evaluation_name, target, data, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, **kwargs)\u001b[0m\n\u001b[0;32m    789\u001b[0m batch_run_data \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(data)\n\u001b[1;32m--> 791\u001b[0m input_data_df, target_generated_columns, target_run \u001b[38;5;241m=\u001b[39m _apply_target_to_data(\n\u001b[0;32m    792\u001b[0m     target, data, batch_run_client, input_data_df, evaluation_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    793\u001b[0m )\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m evaluator_name, mapping \u001b[38;5;129;01min\u001b[39;00m column_mapping\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\azure\\ai\\evaluation\\_evaluate\\_evaluate.py:528\u001b[0m, in \u001b[0;36m_apply_target_to_data\u001b[1;34m(target, data, batch_client, initial_data, evaluation_name, **kwargs)\u001b[0m\n\u001b[0;32m    517\u001b[0m     run \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m    518\u001b[0m         ProxyRun,\n\u001b[0;32m    519\u001b[0m         batch_client\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    525\u001b[0m         ),\n\u001b[0;32m    526\u001b[0m     )\n\u001b[1;32m--> 528\u001b[0m target_output: pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    529\u001b[0m run_summary \u001b[38;5;241m=\u001b[39m batch_client\u001b[38;5;241m.\u001b[39mget_run_summary(run)\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\azure\\ai\\evaluation\\_evaluate\\_batch_run\\proxy_client.py:74\u001b[0m, in \u001b[0;36mProxyClient.get_details\u001b[1;34m(self, client_run, all_results)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_details\u001b[39m(\u001b[38;5;28mself\u001b[39m, client_run: BatchClientRun, all_results: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m---> 74\u001b[0m     run: Run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     result_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pf_client\u001b[38;5;241m.\u001b[39mget_details(run, all_results\u001b[38;5;241m=\u001b[39mall_results)\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\azure\\ai\\evaluation\\_evaluate\\_batch_run\\proxy_client.py:109\u001b[0m, in \u001b[0;36mProxyClient.get_result\u001b[1;34m(run)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_result\u001b[39m(run: BatchClientRun) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Run:\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mProxyRun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\promptflow\\_sdk\\_pf_client.py:301\u001b[0m, in \u001b[0;36mPFClient.run\u001b[1;34m(self, flow, data, run, column_mapping, variant, connections, environment_variables, name, display_name, tags, resume_from, code, init, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run flow against provided data or run.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m.. note::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;124;03m:rtype: ~promptflow.entities.Run\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\n\u001b[0;32m    302\u001b[0m     flow\u001b[38;5;241m=\u001b[39mflow,\n\u001b[0;32m    303\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m    304\u001b[0m     run\u001b[38;5;241m=\u001b[39mrun,\n\u001b[0;32m    305\u001b[0m     column_mapping\u001b[38;5;241m=\u001b[39mcolumn_mapping,\n\u001b[0;32m    306\u001b[0m     variant\u001b[38;5;241m=\u001b[39mvariant,\n\u001b[0;32m    307\u001b[0m     connections\u001b[38;5;241m=\u001b[39mconnections,\n\u001b[0;32m    308\u001b[0m     environment_variables\u001b[38;5;241m=\u001b[39menvironment_variables,\n\u001b[0;32m    309\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    310\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mdisplay_name,\n\u001b[0;32m    311\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    312\u001b[0m     resume_from\u001b[38;5;241m=\u001b[39mresume_from,\n\u001b[0;32m    313\u001b[0m     code\u001b[38;5;241m=\u001b[39mcode,\n\u001b[0;32m    314\u001b[0m     init\u001b[38;5;241m=\u001b[39minit,\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    316\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\promptflow\\_sdk\\_pf_client.py:226\u001b[0m, in \u001b[0;36mPFClient._run\u001b[1;34m(self, flow, data, run, column_mapping, variant, connections, environment_variables, properties, name, display_name, tags, resume_from, code, init, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m run \u001b[38;5;241m=\u001b[39m Run(\n\u001b[0;32m    211\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    212\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mdisplay_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m     dynamic_callable\u001b[38;5;241m=\u001b[39mdynamic_callable,\n\u001b[0;32m    225\u001b[0m )\n\u001b[1;32m--> 226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruns\u001b[38;5;241m.\u001b[39mcreate_or_update(run\u001b[38;5;241m=\u001b[39mrun, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\promptflow\\_sdk\\_telemetry\\activity.py:265\u001b[0m, in \u001b[0;36mmonitor_operation.<locals>.monitor.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m     thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\promptflow\\_sdk\\operations\\_run_operations.py:135\u001b[0m, in \u001b[0;36mRunOperations.create_or_update\u001b[1;34m(self, run, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpromptflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_orchestrator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunSubmitter\n\u001b[1;32m--> 135\u001b[0m created_run \u001b[38;5;241m=\u001b[39m RunSubmitter(client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client)\u001b[38;5;241m.\u001b[39msubmit(run\u001b[38;5;241m=\u001b[39mrun, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\promptflow\\_sdk\\_orchestrator\\run_submitter.py:52\u001b[0m, in \u001b[0;36mRunSubmitter.submit\u001b[1;34m(self, run, stream, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m     wait(tasks, return_when\u001b[38;5;241m=\u001b[39mALL_COMPLETED)\n\u001b[1;32m---> 52\u001b[0m     task_results \u001b[38;5;241m=\u001b[39m [task\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks]\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# upload run to cloud if the trace destination is set to cloud\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\promptflow\\_sdk\\_orchestrator\\run_submitter.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     51\u001b[0m     wait(tasks, return_when\u001b[38;5;241m=\u001b[39mALL_COMPLETED)\n\u001b[1;32m---> 52\u001b[0m     task_results \u001b[38;5;241m=\u001b[39m [\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks]\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# upload run to cloud if the trace destination is set to cloud\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\promptflow\\_sdk\\_orchestrator\\run_submitter.py:134\u001b[0m, in \u001b[0;36mRunSubmitter._run_bulk\u001b[1;34m(self, run, stream, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m flow_overwrite_context(\n\u001b[0;32m    132\u001b[0m     flow_obj, tuning_node, variant, connections\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39mconnections, init_kwargs\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39minit\n\u001b[0;32m    133\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m flow:\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submit_bulk_run(flow\u001b[38;5;241m=\u001b[39mflow, run\u001b[38;5;241m=\u001b[39mrun, local_storage\u001b[38;5;241m=\u001b[39mlocal_storage, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\promptflow\\_sdk\\_orchestrator\\run_submitter.py:227\u001b[0m, in \u001b[0;36mRunSubmitter._submit_bulk_run\u001b[1;34m(self, flow, run, local_storage, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# won't raise the exception since it's already included in run object.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# persist snapshot and result\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# snapshot: flow directory\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     \u001b[43mlocal_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump_snapshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# persist inputs, outputs and metrics\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\promptflow\\_sdk\\operations\\_local_storage_operations.py:256\u001b[0m, in \u001b[0;36mLocalStorageOperations.dump_snapshot\u001b[1;34m(self, flow)\u001b[0m\n\u001b[0;32m    255\u001b[0m patterns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run\u001b[38;5;241m.\u001b[39m_output_path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 256\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopytree\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_posix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_snapshot_folder_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_patterns\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpatterns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_prompty_flow:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# for flex flow and DAG flow, the YAML will be updated.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;66;03m# replace the YAML file with the override one\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\shutil.py:559\u001b[0m, in \u001b[0;36mcopytree\u001b[1;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[0;32m    558\u001b[0m     entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itr)\n\u001b[1;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_copytree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mentries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mignore_dangling_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_dangling_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\shutil.py:513\u001b[0m, in \u001b[0;36m_copytree\u001b[1;34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors:\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(errors)\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "\u001b[1;31mError\u001b[0m: [('C:/Users/akaruparti/OneDrive - Microsoft/Documents/Code With/Akin Gump/evals\\\\results.jsonl', 'C:\\\\Users\\\\akaruparti\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_None_20250616_162421_520056\\\\snapshot\\\\results.jsonl', \"[Errno 2] No such file or directory: 'C:/Users/akaruparti/OneDrive - Microsoft/Documents/Code With/Akin Gump/evals\\\\\\\\results.jsonl'\")]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mEvaluationException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(pathlib\u001b[38;5;241m.\u001b[39mPath(pathlib\u001b[38;5;241m.\u001b[39mPath\u001b[38;5;241m.\u001b[39mcwd())) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data__2.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(path)\n\u001b[1;32m---> 28\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEval-Run-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mazure_deployment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/data_2.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModelEndpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgroundedness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroundedness_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent_safety\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_safety_evaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoherence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoherence_evaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelevance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevance_evaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgroundedness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroundedness_evaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfluency\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfluency_evaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimilarity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_evaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#\"friendliness\": friendliness_eval #custom evaluator\u001b[39;49;00m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# column mapping\u001b[39;49;00m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluator_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent_safety\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumn_mapping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.query}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoherence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumn_mapping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.query}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelevance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumn_mapping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.context}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.query}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgroundedness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumn_mapping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.context}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.query}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfluency\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumn_mapping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.context}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.query}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimilarity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumn_mapping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.context}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.query}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfriendliness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumn_mapping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.context}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.query}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Optionally provide your Azure AI project information to track your evaluation results in your Azure AI project\u001b[39;49;00m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mazure_ai_project\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mazure_ai_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# # Optionally provide an output path to dump a json of metric summary, row level data and metric and Azure AI project URL\u001b[39;49;00m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\akaruparti\\OneDrive - Microsoft\\Documents\\Code With\\Akin Gump\\evals\\.venv\\lib\\site-packages\\azure\\ai\\evaluation\\_evaluate\\_evaluate.py:713\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(data, evaluators, evaluation_name, target, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, **kwargs)\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;66;03m# Ensure a consistent user experience when encountering errors by converting\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;66;03m# all other exceptions to EvaluationException.\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EvaluationException):\n\u001b[1;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EvaluationException(\n\u001b[0;32m    714\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    715\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mEVALUATE,\n\u001b[0;32m    716\u001b[0m         category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mFAILED_EXECUTION,\n\u001b[0;32m    717\u001b[0m         blame\u001b[38;5;241m=\u001b[39mErrorBlame\u001b[38;5;241m.\u001b[39mSYSTEM_ERROR,\n\u001b[0;32m    718\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[1;31mEvaluationException\u001b[0m: (InternalError) [('C:/Users/akaruparti/OneDrive - Microsoft/Documents/Code With/Akin Gump/evals\\\\results.jsonl', 'C:\\\\Users\\\\akaruparti\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_None_20250616_162421_520056\\\\snapshot\\\\results.jsonl', \"[Errno 2] No such file or directory: 'C:/Users/akaruparti/OneDrive - Microsoft/Documents/Code With/Akin Gump/evals\\\\\\\\results.jsonl'\")]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "from azure.ai.evaluation import evaluate\n",
    "from azure.ai.evaluation import (\n",
    "    ContentSafetyEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    CoherenceEvaluator,\n",
    "    GroundednessEvaluator,\n",
    "    FluencyEvaluator,\n",
    "    SimilarityEvaluator,\n",
    ")\n",
    "from model_endpoint import ModelEndpoint\n",
    "\n",
    "# Disable local snapshot to speed up evaluation\n",
    "os.environ[\"PROMPTFLOW_DISABLE_LOCAL_SNAPSHOT\"] = \"true\"\n",
    "\n",
    "content_safety_evaluator = ContentSafetyEvaluator(\n",
    "    azure_ai_project=azure_ai_project, credential=DefaultAzureCredential()\n",
    ")\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "coherence_evaluator = CoherenceEvaluator(model_config)\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
    "fluency_evaluator = FluencyEvaluator(model_config)\n",
    "similarity_evaluator = SimilarityEvaluator(model_config)\n",
    "\n",
    "# Create proper output path\n",
    "output_path = str(Path.cwd() / \"results.jsonl\")\n",
    "print(f\"Output path: {output_path}\")\n",
    "\n",
    "# Pre-create the results file to avoid snapshot copy issues\n",
    "Path(\"results.jsonl\").touch()\n",
    "\n",
    "results = evaluate(\n",
    "    evaluation_name=\"Eval-Run-\" + \"-\" + model_config[\"azure_deployment\"].title(),\n",
    "    data= \"./data/data_2.jsonl\",\n",
    "    target=ModelEndpoint(model_config),\n",
    "    evaluators={\n",
    "        \"content_safety\": content_safety_evaluator,\n",
    "        \"coherence\": coherence_evaluator,\n",
    "        \"relevance\": relevance_evaluator,\n",
    "        \"groundedness\": groundedness_evaluator,\n",
    "        \"fluency\": fluency_evaluator,\n",
    "        \"similarity\": similarity_evaluator,\n",
    "        #\"friendliness\": friendliness_eval #custom evaluator\n",
    "    },\n",
    "    # column mapping\n",
    "    evaluator_config={\n",
    "        \"content_safety\": {\"column_mapping\": {\"query\": \"${data.query}\", \"response\": \"${data.response}\"}},\n",
    "        \"coherence\": {\"column_mapping\": {\"response\": \"${data.response}\", \"query\": \"${data.query}\"}},\n",
    "        \"relevance\": {\n",
    "            \"column_mapping\": {\"response\": \"${data.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"groundedness\": {\n",
    "            \"column_mapping\": {\n",
    "                \"response\": \"${data.response}\",\n",
    "                \"context\": \"${data.context}\",\n",
    "                \"query\": \"${data.query}\",\n",
    "            }\n",
    "        },\n",
    "        \"fluency\": {\n",
    "            \"column_mapping\": {\"response\": \"${data.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"similarity\": {\n",
    "            \"column_mapping\": {\"response\": \"${data.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"friendliness\": {\n",
    "            \"column_mapping\": {\"response\": \"${data.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # Optionally provide your Azure AI project information to track your evaluation results in your Azure AI project\n",
    "    azure_ai_project = azure_ai_project,\n",
    "    # Use proper output path\n",
    "    output_path=output_path\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37295451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outputs.query</th>\n",
       "      <th>outputs.response</th>\n",
       "      <th>inputs.query</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.ground_truth</th>\n",
       "      <th>outputs.groundedness.groundedness</th>\n",
       "      <th>outputs.groundedness.gpt_groundedness</th>\n",
       "      <th>outputs.groundedness.groundedness_reason</th>\n",
       "      <th>outputs.groundedness.groundedness_result</th>\n",
       "      <th>outputs.groundedness.groundedness_threshold</th>\n",
       "      <th>...</th>\n",
       "      <th>outputs.relevance.relevance_result</th>\n",
       "      <th>outputs.relevance.relevance_threshold</th>\n",
       "      <th>outputs.fluency.fluency</th>\n",
       "      <th>outputs.fluency.gpt_fluency</th>\n",
       "      <th>outputs.fluency.fluency_reason</th>\n",
       "      <th>outputs.fluency.fluency_result</th>\n",
       "      <th>outputs.fluency.fluency_threshold</th>\n",
       "      <th>outputs.friendliness.score</th>\n",
       "      <th>outputs.friendliness.reason</th>\n",
       "      <th>line_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>France is the country in Europe.</td>\n",
       "      <td>Paris</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE introduces information about the ...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The response is clear and grammatically correc...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The response is neutral, providing factual inf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which tent is the most waterproof?</td>\n",
       "      <td>When looking for the most waterproof tent, the...</td>\n",
       "      <td>Which tent is the most waterproof?</td>\n",
       "      <td>#TrailMaster X4 Tent, price $250,## BrandOutdo...</td>\n",
       "      <td>The TrailMaster X4 tent has a rainfly waterpro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The RESPONSE is completely ungrounded as it in...</td>\n",
       "      <td>fail</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is well-articulated with good con...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is mostly friendly, providing det...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which camping table is the lightest?</td>\n",
       "      <td>The lightest camping table available can vary ...</td>\n",
       "      <td>Which camping table is the lightest?</td>\n",
       "      <td>#BaseCamp Folding Table, price $60,## BrandCam...</td>\n",
       "      <td>The BaseCamp Folding Table has a weight of 15 lbs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The RESPONSE is entirely unrelated to the CONT...</td>\n",
       "      <td>fail</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is well-articulated, with good co...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is informative and helpful, provi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How much does TrailWalker Hiking Shoes cost?</td>\n",
       "      <td>I don't have real-time access to current prici...</td>\n",
       "      <td>How much does TrailWalker Hiking Shoes cost?</td>\n",
       "      <td>#TrailWalker Hiking Shoes, price $110## BrandT...</td>\n",
       "      <td>The TrailWalker Hiking Shoes are priced at $110</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE does not include the specific det...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is well-articulated, demonstratin...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is informative and helpful, provi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   outputs.query  \\\n",
       "0                 What is the capital of France?   \n",
       "1             Which tent is the most waterproof?   \n",
       "2           Which camping table is the lightest?   \n",
       "3  How much does TrailWalker Hiking Shoes cost?    \n",
       "\n",
       "                                    outputs.response  \\\n",
       "0                    The capital of France is Paris.   \n",
       "1  When looking for the most waterproof tent, the...   \n",
       "2  The lightest camping table available can vary ...   \n",
       "3  I don't have real-time access to current prici...   \n",
       "\n",
       "                                    inputs.query  \\\n",
       "0                 What is the capital of France?   \n",
       "1             Which tent is the most waterproof?   \n",
       "2           Which camping table is the lightest?   \n",
       "3  How much does TrailWalker Hiking Shoes cost?    \n",
       "\n",
       "                                      inputs.context  \\\n",
       "0                   France is the country in Europe.   \n",
       "1  #TrailMaster X4 Tent, price $250,## BrandOutdo...   \n",
       "2  #BaseCamp Folding Table, price $60,## BrandCam...   \n",
       "3  #TrailWalker Hiking Shoes, price $110## BrandT...   \n",
       "\n",
       "                                 inputs.ground_truth  \\\n",
       "0                                              Paris   \n",
       "1  The TrailMaster X4 tent has a rainfly waterpro...   \n",
       "2  The BaseCamp Folding Table has a weight of 15 lbs   \n",
       "3    The TrailWalker Hiking Shoes are priced at $110   \n",
       "\n",
       "   outputs.groundedness.groundedness  outputs.groundedness.gpt_groundedness  \\\n",
       "0                                  3                                      3   \n",
       "1                                  1                                      1   \n",
       "2                                  1                                      1   \n",
       "3                                  3                                      3   \n",
       "\n",
       "            outputs.groundedness.groundedness_reason  \\\n",
       "0  The RESPONSE introduces information about the ...   \n",
       "1  The RESPONSE is completely ungrounded as it in...   \n",
       "2  The RESPONSE is entirely unrelated to the CONT...   \n",
       "3  The RESPONSE does not include the specific det...   \n",
       "\n",
       "  outputs.groundedness.groundedness_result  \\\n",
       "0                                     pass   \n",
       "1                                     fail   \n",
       "2                                     fail   \n",
       "3                                     pass   \n",
       "\n",
       "   outputs.groundedness.groundedness_threshold  ...  \\\n",
       "0                                            3  ...   \n",
       "1                                            3  ...   \n",
       "2                                            3  ...   \n",
       "3                                            3  ...   \n",
       "\n",
       "  outputs.relevance.relevance_result  outputs.relevance.relevance_threshold  \\\n",
       "0                               pass                                      3   \n",
       "1                               pass                                      3   \n",
       "2                               pass                                      3   \n",
       "3                               pass                                      3   \n",
       "\n",
       "  outputs.fluency.fluency  outputs.fluency.gpt_fluency  \\\n",
       "0                       3                            3   \n",
       "1                       4                            4   \n",
       "2                       4                            4   \n",
       "3                       4                            4   \n",
       "\n",
       "                      outputs.fluency.fluency_reason  \\\n",
       "0  The response is clear and grammatically correc...   \n",
       "1  The response is well-articulated with good con...   \n",
       "2  The response is well-articulated, with good co...   \n",
       "3  The response is well-articulated, demonstratin...   \n",
       "\n",
       "  outputs.fluency.fluency_result  outputs.fluency.fluency_threshold  \\\n",
       "0                           pass                                  3   \n",
       "1                           pass                                  3   \n",
       "2                           pass                                  3   \n",
       "3                           pass                                  3   \n",
       "\n",
       "  outputs.friendliness.score  \\\n",
       "0                          3   \n",
       "1                          4   \n",
       "2                          4   \n",
       "3                          4   \n",
       "\n",
       "                         outputs.friendliness.reason line_number  \n",
       "0  The response is neutral, providing factual inf...           0  \n",
       "1  The response is mostly friendly, providing det...           1  \n",
       "2  The response is informative and helpful, provi...           2  \n",
       "3  The response is informative and helpful, provi...           3  \n",
       "\n",
       "[4 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the JSON content from the file \"results.jsonl\"\n",
    "with open(\"results.jsonl\", \"r\") as f:\n",
    "\tjsonl_text = f.read()\n",
    "\n",
    "data = json.loads(jsonl_text)\n",
    "\n",
    "# Create a DataFrame using the \"rows\" key from the JSON data\n",
    "df = pd.DataFrame(data.get(\"rows\", []))\n",
    "\n",
    "# Convert the DataFrame to CSV format as a string\n",
    "csv_content = df.to_csv(index=False)\n",
    "# Display the DataFrame as a table in the notebook\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e191221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3df5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
