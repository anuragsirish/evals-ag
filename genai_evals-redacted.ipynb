{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation with Azure AI Foundry\n",
    "\n",
    "This notebook demonstrates how to evaluate data using custom evaluators and send the results to [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-studio/what-is-ai-studio).\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- An Azure subscription.\n",
    "- An Azure AI Foundry workspace.\n",
    "- An Azure AI Foundry project.\n",
    "- An Azure OpenAI resource.\n",
    "\n",
    "### Install the required packages\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Create the following environment variables or add them to an `.env` file\n",
    "\n",
    "```bash\n",
    "AZURE_OPENAI_ENDPOINT=<your-azure-openai-endpoint>\n",
    "AZURE_OPENAI_API_KEY=<your-azure-openai-api-key>\n",
    "AZURE_OPENAI_DEPLOYMENT=<your-azure-openai-deployment>\n",
    "AZURE_OPENAI_API_VERSION=<your-azure-openai-api-version>\n",
    "AZURE_SUBSCRIPTION_ID=<your-azure-subscription-id>\n",
    "AZURE_RESOURCE_GROUP=<your-azure-resource-group>\n",
    "AZURE_AI_FOUNDRY_PROJECT=<your-azure-azure_foundry_project>\n",
    "```\n",
    "\n",
    "### References\n",
    "\n",
    "- [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-studio/what-is-ai-studio)\n",
    "- [Evaluate your Generative AI application locally with the Azure AI Evaluation SDK](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/develop/evaluate-sdk#evaluating-direct-and-indirect-attack-jailbreak-vulnerability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff337f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc35897",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630cdd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a49ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from promptflow.core import AzureOpenAIModelConfiguration\n",
    "from promptflow.tracing import start_trace\n",
    "\n",
    "if \"AZURE_OPENAI_API_KEY\" not in os.environ:\n",
    "    # load environment variables from .env file\n",
    "    load_dotenv()\n",
    "\n",
    "# start a trace session, and print a url for user to check trace\n",
    "start_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03acbd3",
   "metadata": {},
   "source": [
    "## Setup Credentials and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2926c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.getenv(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.getenv(\"AZURE_RESOURCE_GROUP\"),\n",
    "    \"project_name\": os.getenv(\"AZURE_AI_FOUNDRY_PROJECT\"),\n",
    "}\n",
    "\n",
    "\n",
    "model_config = {\n",
    "    \"api_key\":os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"azure_deployment\": os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "configuration = AzureOpenAIModelConfiguration(\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ccaf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(azure_ai_project)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad60c55",
   "metadata": {},
   "source": [
    "## Groundedness Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import GroundednessProEvaluator, GroundednessEvaluator\n",
    "\n",
    "# Initializing Groundedness and Groundedness Pro evaluators\n",
    "groundedness_eval = GroundednessEvaluator(model_config, threshold=3)\n",
    "\n",
    "query_response_pass = dict(\n",
    "    query=\"Is it allowed to bring bottled water on domestic flights?\",\n",
    "    context=\"\",\n",
    "    response=\"No. According to the airline regulations, passengers are not permitted to bring bottled water through security checkpoints. Only liquids purchased after the security screening are allowed on board. This rule is in place to ensure passenger safety and comply with transportation security guidelines.\"\n",
    ")\n",
    "\n",
    "query_response_fail = dict(\n",
    "    query=\"Is it allowed to bring bottled water on domestic flights?\",\n",
    "    context=\"\",\n",
    "    response=\"Yes. You can bring any amount of bottled water on a plane without restrictions. There are no rules about liquids on domestic flights.\"\n",
    ")\n",
    "\n",
    "# Running Groundedness Evaluator on a query and response pair\n",
    "groundedness_score = groundedness_eval(\n",
    "    **query_response_fail\n",
    ")\n",
    "print(groundedness_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e23aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "with open(\"data/data.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        result = groundedness_eval(\n",
    "            query=item[\"query\"],\n",
    "            context=item.get(\"context\", \"\"),\n",
    "            response=item[\"ground_truth\"]\n",
    "        )\n",
    "        records.append({\n",
    "            \"query\": item[\"query\"],\n",
    "            \"response\": item[\"ground_truth\"],\n",
    "            \"groundedness\": result[\"groundedness\"],\n",
    "            \"groundedness_reason\": result[\"groundedness_reason\"],\n",
    "            \"groundedness_result\": result[\"groundedness_result\"],\n",
    "            \"groundedness_threshold\": result[\"groundedness_threshold\"],\n",
    "        })\n",
    "\n",
    "# Load into a DataFrame and display\n",
    "df = pd.DataFrame(records)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8753b1",
   "metadata": {},
   "source": [
    "## Relevance Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b3e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import RelevanceEvaluator\n",
    "\n",
    "# Initialazing Groundedness and Groundedness Pro evaluators\n",
    "relevance_eval = RelevanceEvaluator(model_config, threshold=3)\n",
    "\n",
    "query_response_pass = dict(\n",
    "    query=\"Is it allowed to bring bottled water on domestic flights?\",\n",
    "    context=\"\",\n",
    "    response=\"No. According to the airline regulations, passengers are not permitted to bring bottled water through security checkpoints. Only liquids purchased after the security screening are allowed on board. This rule is in place to ensure passenger safety and comply with transportation security guidelines.\"\n",
    ")\n",
    "\n",
    "query_response_fail = dict(\n",
    "    query=\"Is it allowed to bring bottled water on domestic flights?\",\n",
    "    context=\"\",\n",
    "    response=\"Yes. You can bring any amount of bottled water on a plane without restrictions. There are no rules about liquids on domestic flights.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Running Groundedness Evaluator on a query and response pair\n",
    "relevance_eval_score = relevance_eval(\n",
    "    **query_response_pass\n",
    ")\n",
    "print(relevance_eval_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b82166",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "with open(\"data/data.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        result = relevance_eval(\n",
    "            query=item[\"query\"],\n",
    "            context=item.get(\"context\", \"\"),\n",
    "            response=item[\"ground_truth\"]\n",
    "        )\n",
    "        records.append({\n",
    "            \"query\":       item[\"query\"],\n",
    "            \"response\":    item[\"ground_truth\"],\n",
    "            \"relevance\":   result[\"relevance\"],\n",
    "            \"relevant_reason\": result[\"relevance_reason\"],\n",
    "            \"relevant_result\": result[\"relevance_result\"],\n",
    "            \"relevant_threshold\": result[\"relevance_threshold\"],\n",
    "         \n",
    "        })\n",
    "\n",
    "# 3. Load into a DataFrame and display\n",
    "df = pd.DataFrame(records)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a585ed",
   "metadata": {},
   "source": [
    "## Friendliness Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from friendliness.friendliness import FriendlinessEvaluator\n",
    "\n",
    "friendliness_eval = FriendlinessEvaluator(configuration)\n",
    "\n",
    "friendliness_score = friendliness_eval(response=\"I will not apologize for my behavior!\")\n",
    "\n",
    "print(friendliness_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a2808a",
   "metadata": {},
   "source": [
    "## Evaluate with both built-in and custom evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "from azure.ai.evaluation import evaluate\n",
    "from azure.ai.evaluation import (\n",
    "    ContentSafetyEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    CoherenceEvaluator,\n",
    "    GroundednessEvaluator,\n",
    "    FluencyEvaluator,\n",
    "    SimilarityEvaluator,\n",
    ")\n",
    "from model_endpoint import ModelEndpoint\n",
    "\n",
    "# Disable local snapshot to speed up evaluation\n",
    "os.environ[\"PROMPTFLOW_DISABLE_LOCAL_SNAPSHOT\"] = \"true\"\n",
    "\n",
    "content_safety_evaluator = ContentSafetyEvaluator(\n",
    "    azure_ai_project=azure_ai_project, credential=DefaultAzureCredential()\n",
    ")\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "coherence_evaluator = CoherenceEvaluator(model_config)\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
    "fluency_evaluator = FluencyEvaluator(model_config)\n",
    "similarity_evaluator = SimilarityEvaluator(model_config)\n",
    "\n",
    "# Create proper output path\n",
    "output_path = str(Path.cwd() / \"results.jsonl\")\n",
    "print(f\"Output path: {output_path}\")\n",
    "\n",
    "# Pre-create the results file to avoid snapshot copy issues\n",
    "Path(\"results.jsonl\").touch()\n",
    "\n",
    "results = evaluate(\n",
    "    evaluation_name=\"Eval-Run-\" + \"-\" + model_config[\"azure_deployment\"].title(),\n",
    "    data= \"./data/data_3.jsonl\",\n",
    "    target=ModelEndpoint(model_config),\n",
    "    evaluators={\n",
    "        \"content_safety\": content_safety_evaluator,\n",
    "        \"coherence\": coherence_evaluator,\n",
    "        \"relevance\": relevance_evaluator,\n",
    "        \"groundedness\": groundedness_evaluator,\n",
    "        \"fluency\": fluency_evaluator,\n",
    "        \"similarity\": similarity_evaluator,\n",
    "        \"friendliness\": friendliness_eval #custom evaluator\n",
    "    },\n",
    "    # column mapping\n",
    "    evaluator_config={\n",
    "        \"content_safety\": {\"column_mapping\": {\"query\": \"${data.query}\", \"response\": \"${data.response}\"}},\n",
    "        \"coherence\": {\"column_mapping\": {\"response\": \"${data.response}\", \"query\": \"${data.query}\"}},\n",
    "        \"relevance\": {\n",
    "            \"column_mapping\": {\"response\": \"${data.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"groundedness\": {\n",
    "            \"column_mapping\": {\n",
    "                \"response\": \"${data.response}\",\n",
    "                \"context\": \"${data.context}\",\n",
    "                \"query\": \"${data.query}\",\n",
    "            }\n",
    "        },\n",
    "        \"fluency\": {\n",
    "            \"column_mapping\": {\"response\": \"${data.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"similarity\": {\n",
    "            \"column_mapping\": {\"response\": \"${data.response}\", \"ground_truth\": \"${data.ground_truth}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"friendliness\": {\n",
    "            \"column_mapping\": {\"response\": \"${data.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # Optionally provide your Azure AI project information to track your evaluation results in your Azure AI project\n",
    "    azure_ai_project = azure_ai_project,\n",
    "    # Use proper output path\n",
    "    output_path=output_path\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37295451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the JSON content from the file \"results.jsonl\"\n",
    "with open(\"results.jsonl\", \"r\") as f:\n",
    "\tjsonl_text = f.read()\n",
    "\n",
    "data = json.loads(jsonl_text)\n",
    "\n",
    "# Create a DataFrame using the \"rows\" key from the JSON data\n",
    "df = pd.DataFrame(data.get(\"rows\", []))\n",
    "\n",
    "# Convert the DataFrame to CSV format as a string\n",
    "csv_content = df.to_csv(index=False)\n",
    "# Display the DataFrame as a table in the notebook\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e191221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3df5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
